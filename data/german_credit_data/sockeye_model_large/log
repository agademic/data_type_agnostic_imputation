[2020-02-04:11:49:17:INFO:sockeye.utils:log_sockeye_version] Sockeye version 1.18.106, commit 49e46b25efde2f9b4a753e1cbd47b63b36c73e5f, path /Users/a.gogohia/anaconda3/envs/sockeye/lib/python3.7/site-packages/sockeye/__init__.py
[2020-02-04:11:49:17:INFO:sockeye.utils:log_mxnet_version] MXNet version 1.5.0, path /Users/a.gogohia/anaconda3/envs/sockeye/lib/python3.7/site-packages/mxnet/__init__.py
[2020-02-04:11:49:17:INFO:sockeye.utils:log_basic_info] Command: /Users/a.gogohia/anaconda3/envs/sockeye/lib/python3.7/site-packages/sockeye/train.py -d german_credit_data/prepared_sockeye_data/ -vs german_credit_data/dev.source -vt german_credit_data/dev.target -vsf german_credit_data/dev.source_factors --num-embed 32 --source-factors-num-embed 16 --transformer-model-size 32 --transformer-feed-forward-num-hidden 16 --num-layers 4 --metrics perplexity accuracy --use-cpu --batch-type sentence --max-num-checkpoint-not-improved 3 --batch-size 4 --overwrite-output -o german_credit_data/sockeye_model_large
[2020-02-04:11:49:17:INFO:sockeye.utils:log_basic_info] Arguments: Namespace(allow_missing_params=False, attention_based_copying=False, batch_size=4, batch_type='sentence', bucket_width=10, checkpoint_interval=4000, cnn_activation_type='glu', cnn_hidden_dropout=0.2, cnn_kernel_width=(3, 3), cnn_num_hidden=512, cnn_positional_embedding_type='learned', cnn_project_qkv=False, config=None, conv_embed_add_positional_encodings=False, conv_embed_dropout=0.0, conv_embed_max_filter_width=8, conv_embed_num_filters=(200, 200, 250, 250, 300, 300, 300, 300), conv_embed_num_highway_layers=4, conv_embed_output_dim=None, conv_embed_pool_stride=5, decode_and_evaluate=500, decode_and_evaluate_device_id=None, decode_and_evaluate_use_cpu=False, decoder='transformer', decoder_only=False, device_ids=[-1], disable_device_locking=False, dry_run=False, embed_dropout=(0.0, 0.0), embed_weight_init='default', encoder='transformer', fixed_param_names=[], fixed_param_strategy=None, gradient_clipping_threshold=1.0, gradient_clipping_type='none', gradient_compression_threshold=0.5, gradient_compression_type=None, initial_learning_rate=0.0002, keep_initializations=False, keep_last_params=-1, kvstore='device', label_smoothing=0.1, layer_normalization=False, learning_rate_decay_optimizer_states_reset='off', learning_rate_decay_param_reset=False, learning_rate_half_life=10, learning_rate_reduce_factor=0.7, learning_rate_reduce_num_not_improved=8, learning_rate_schedule=None, learning_rate_scheduler_type='plateau-reduce', learning_rate_warmup=0, length_task=None, length_task_layers=1, length_task_weight=1.0, lhuc=None, lock_dir='/tmp', loglevel='INFO', loss='cross-entropy', loss_normalization_type='valid', max_checkpoints=None, max_num_checkpoint_not_improved=3, max_num_epochs=None, max_samples=None, max_seconds=None, max_seq_len=(99, 99), max_updates=None, metrics=['perplexity', 'accuracy'], min_num_epochs=None, min_samples=None, min_updates=None, momentum=None, monitor_pattern=None, monitor_stat_func='mx_default', no_bucketing=False, num_embed=(32, 32), num_layers=(4, 4), num_words=(0, 0), optimized_metric='perplexity', optimizer='adam', optimizer_params=None, output='german_credit_data/sockeye_model_large', overwrite_output=True, pad_vocab_to_multiple_of=None, params=None, prepared_data='german_credit_data/prepared_sockeye_data/', quiet=False, rnn_attention_coverage_max_fertility=2, rnn_attention_coverage_num_hidden=1, rnn_attention_coverage_type='count', rnn_attention_in_upper_layers=False, rnn_attention_mhdot_heads=None, rnn_attention_num_hidden=None, rnn_attention_type='mlp', rnn_attention_use_prev_word=False, rnn_cell_type='lstm', rnn_context_gating=False, rnn_decoder_hidden_dropout=0.2, rnn_decoder_state_init='last', rnn_dropout_inputs=(0.0, 0.0), rnn_dropout_recurrent=(0.0, 0.0), rnn_dropout_states=(0.0, 0.0), rnn_enc_last_hidden_concat_to_embedding=False, rnn_encoder_reverse_input=False, rnn_first_residual_layer=2, rnn_forget_bias=0.0, rnn_h2h_init='orthogonal', rnn_num_hidden=1024, rnn_residual_connections=False, rnn_scale_dot_attention=False, seed=13, shared_vocab=False, source=None, source_factor_vocabs=[], source_factors=[], source_factors_combine='concat', source_factors_num_embed=[16], source_vocab=None, stop_training_on_decoder_failure=False, target=None, target_vocab=None, transformer_activation_type='relu', transformer_attention_heads=(8, 8), transformer_dropout_act=0.1, transformer_dropout_attention=0.1, transformer_dropout_prepost=0.1, transformer_feed_forward_num_hidden=(16, 16), transformer_model_size=(32, 32), transformer_positional_embedding_type='fixed', transformer_postprocess=('dr', 'dr'), transformer_preprocess=('n', 'n'), update_interval=1, use_cpu=True, validation_source='german_credit_data/dev.source', validation_source_factors=['german_credit_data/dev.source_factors'], validation_target='german_credit_data/dev.target', weight_decay=0.0, weight_init='xavier', weight_init_scale=3.0, weight_init_xavier_factor_type='avg', weight_init_xavier_rand_type='uniform', weight_normalization=False, weight_tying=False, weight_tying_type='trg_softmax', word_min_count=(1, 1))
[2020-02-04:11:49:17:INFO:__main__:train] Adjusting maximum length to reserve space for a BOS/EOS marker. New maximum length: (100, 100)
[2020-02-04:11:49:17:INFO:__main__:train] Training Device(s): cpu(0)
[2020-02-04:11:49:17:INFO:sockeye.data_io:get_prepared_data_iters] ===============================
[2020-02-04:11:49:17:INFO:sockeye.data_io:get_prepared_data_iters] Creating training data iterator
[2020-02-04:11:49:17:INFO:sockeye.data_io:get_prepared_data_iters] ===============================
[2020-02-04:11:49:17:INFO:sockeye.vocab:vocab_from_json] Vocabulary (35 words) loaded from "german_credit_data/prepared_sockeye_data/vocab.src.0.json"
[2020-02-04:11:49:17:INFO:sockeye.vocab:vocab_from_json] Vocabulary (24 words) loaded from "german_credit_data/prepared_sockeye_data/vocab.src.1.json"
[2020-02-04:11:49:17:INFO:sockeye.vocab:vocab_from_json] Vocabulary (9 words) loaded from "german_credit_data/prepared_sockeye_data/vocab.trg.0.json"
[2020-02-04:11:49:17:INFO:sockeye.data_io:log] Tokens: source 77215 target 4225
[2020-02-04:11:49:17:INFO:sockeye.data_io:log] Vocabulary coverage: source 100% target 100%
[2020-02-04:11:49:17:INFO:sockeye.data_io:log] 900 sequences across 100 buckets
[2020-02-04:11:49:17:INFO:sockeye.data_io:log] 0 sequences did not fit into buckets and were discarded
[2020-02-04:11:49:17:INFO:sockeye.data_io:describe_data_and_buckets] Bucket (90, 9): 900 samples in 225 batches of 4, ~18.8 tokens/batch, trg/src length ratio: 0.05 (+-0.01)
[2020-02-04:11:49:17:INFO:sockeye.data_io:_load_shard] Loading shard german_credit_data/prepared_sockeye_data/shard.00000.
[2020-02-04:11:49:17:INFO:sockeye.data_io:get_validation_data_iter] =================================
[2020-02-04:11:49:17:INFO:sockeye.data_io:get_validation_data_iter] Creating validation data iterator
[2020-02-04:11:49:17:INFO:sockeye.data_io:get_validation_data_iter] =================================
[2020-02-04:11:49:17:INFO:sockeye.data_io:analyze_sequence_lengths] 100 sequences of maximum length (100, 100) in '/Users/a.gogohia/Documents/GitHub/data_type_agnostic_imputation/data/german_credit_data/dev.source' and '/Users/a.gogohia/Documents/GitHub/data_type_agnostic_imputation/data/german_credit_data/dev.target'.
[2020-02-04:11:49:17:INFO:sockeye.data_io:analyze_sequence_lengths] Mean training target/source length ratio: 0.06 (+-0.01)
[2020-02-04:11:49:17:INFO:sockeye.data_io:log] Tokens: source 8578 target 475
[2020-02-04:11:49:17:INFO:sockeye.data_io:log] Vocabulary coverage: source 100% target 100%
[2020-02-04:11:49:17:INFO:sockeye.data_io:log] 100 sequences across 100 buckets
[2020-02-04:11:49:17:INFO:sockeye.data_io:log] 0 sequences did not fit into buckets and were discarded
[2020-02-04:11:49:17:INFO:sockeye.data_io:describe_data_and_buckets] Bucket (90, 9): 100 samples in 25 batches of 4, ~18.8 tokens/batch, trg/src length ratio: 0.06 (+-0.01)
[2020-02-04:11:49:17:INFO:sockeye.data_io:load] Created bucketed parallel data set. Introduced padding: source=4.7% target=47.2%)
[2020-02-04:11:49:17:INFO:sockeye.vocab:vocab_to_json] Vocabulary saved to "/Users/a.gogohia/Documents/GitHub/data_type_agnostic_imputation/data/german_credit_data/sockeye_model_large/vocab.src.0.json"
[2020-02-04:11:49:17:INFO:sockeye.vocab:vocab_to_json] Vocabulary saved to "/Users/a.gogohia/Documents/GitHub/data_type_agnostic_imputation/data/german_credit_data/sockeye_model_large/vocab.src.1.json"
[2020-02-04:11:49:17:INFO:sockeye.vocab:vocab_to_json] Vocabulary saved to "/Users/a.gogohia/Documents/GitHub/data_type_agnostic_imputation/data/german_credit_data/sockeye_model_large/vocab.trg.0.json"
[2020-02-04:11:49:17:INFO:__main__:train] Vocabulary sizes: source=[35|24] target=9
[2020-02-04:11:49:17:INFO:__main__:create_encoder_config] Encoder transformer-model-size adjusted to account for source factor embeddings: 32 -> 48
[2020-02-04:11:49:17:INFO:sockeye.model:__init__] Config[_frozen=True, config_data=Config[_frozen=True, data_statistics=Config[_frozen=True, average_len_target_per_bucket=[None, None, None, None, None, None, None, None, 4.6944444444444535, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None], buckets=[(10, 2), (20, 2), (30, 3), (40, 4), (50, 5), (60, 6), (70, 7), (80, 8), (90, 9), (100, 10), (100, 11), (100, 12), (100, 13), (100, 14), (100, 15), (100, 16), (100, 17), (100, 18), (100, 19), (100, 20), (100, 21), (100, 22), (100, 23), (100, 24), (100, 25), (100, 26), (100, 27), (100, 28), (100, 29), (100, 30), (100, 31), (100, 32), (100, 33), (100, 34), (100, 35), (100, 36), (100, 37), (100, 38), (100, 39), (100, 40), (100, 41), (100, 42), (100, 43), (100, 44), (100, 45), (100, 46), (100, 47), (100, 48), (100, 49), (100, 50), (100, 51), (100, 52), (100, 53), (100, 54), (100, 55), (100, 56), (100, 57), (100, 58), (100, 59), (100, 60), (100, 61), (100, 62), (100, 63), (100, 64), (100, 65), (100, 66), (100, 67), (100, 68), (100, 69), (100, 70), (100, 71), (100, 72), (100, 73), (100, 74), (100, 75), (100, 76), (100, 77), (100, 78), (100, 79), (100, 80), (100, 81), (100, 82), (100, 83), (100, 84), (100, 85), (100, 86), (100, 87), (100, 88), (100, 89), (100, 90), (100, 91), (100, 92), (100, 93), (100, 94), (100, 95), (100, 96), (100, 97), (100, 98), (100, 99), (100, 100)], length_ratio_mean=0.05472421539958924, length_ratio_stats_per_bucket=[(None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (0.05472421539958924, 0.005422177928218876), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None), (None, None)], length_ratio_std=0.005422177928218876, max_observed_len_source=88, max_observed_len_target=5, num_discarded=0, num_sents=900, num_sents_per_bucket=[0, 0, 0, 0, 0, 0, 0, 0, 900, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], num_tokens_source=77215, num_tokens_target=4225, num_unks_source=0, num_unks_target=0, size_vocab_source=35, size_vocab_target=9], max_seq_len_source=100, max_seq_len_target=100, num_source_factors=2, source_with_eos=True], config_decoder=Config[_frozen=True, act_type=relu, attention_heads=8, conv_config=None, dropout_act=0.1, dropout_attention=0.1, dropout_prepost=0.1, dtype=float32, feed_forward_num_hidden=16, lhuc=False, max_seq_len_source=100, max_seq_len_target=100, model_size=32, num_layers=4, positional_embedding_type=fixed, postprocess_sequence=dr, preprocess_sequence=n, use_lhuc=False], config_embed_source=Config[_frozen=True, dropout=0.0, dtype=float32, factor_configs=[Config[_frozen=False, num_embed=16, vocab_size=24]], num_embed=32, num_factors=2, source_factors_combine=concat, vocab_size=35], config_embed_target=Config[_frozen=True, dropout=0.0, dtype=float32, factor_configs=None, num_embed=32, num_factors=1, source_factors_combine=concat, vocab_size=9], config_encoder=Config[_frozen=True, act_type=relu, attention_heads=8, conv_config=None, dropout_act=0.1, dropout_attention=0.1, dropout_prepost=0.1, dtype=float32, feed_forward_num_hidden=16, lhuc=False, max_seq_len_source=100, max_seq_len_target=100, model_size=48, num_layers=4, positional_embedding_type=fixed, postprocess_sequence=dr, preprocess_sequence=n, use_lhuc=False], config_length_task=None, config_length_task_loss=None, config_loss=Config[_frozen=True, label_smoothing=0.1, length_task_link=None, length_task_weight=1.0, name=cross-entropy, normalization_type=valid, vocab_size=9], lhuc=False, num_pointers=0, vocab_source_size=35, vocab_target_size=9, weight_normalization=False, weight_tying=False, weight_tying_type=None]
[2020-02-04:11:49:17:INFO:sockeye.encoder:__init__] sockeye.encoder.EncoderSequence dtype: float32
[2020-02-04:11:49:17:INFO:sockeye.encoder:__init__] sockeye.encoder.AddSinCosPositionalEmbeddings dtype: float32
[2020-02-04:11:49:17:INFO:sockeye.encoder:__init__] sockeye.encoder.TransformerEncoder dtype: float32
[2020-02-04:11:49:17:INFO:sockeye.decoder:__init__] sockeye.decoder.TransformerDecoder dtype: float32
[2020-02-04:11:49:17:INFO:sockeye.encoder:__init__] sockeye.encoder.AddSinCosPositionalEmbeddings dtype: float32
[2020-02-04:11:49:17:INFO:sockeye.encoder:__init__] sockeye.encoder.Embedding dtype: float32
[2020-02-04:11:49:17:INFO:sockeye.encoder:__init__] sockeye.encoder.Embedding dtype: float32
[2020-02-04:11:49:17:INFO:sockeye.loss:__init__] Loss: CrossEntropy(normalization_type=valid, label_smoothing=0.1)
[2020-02-04:11:49:17:INFO:sockeye.training:_initialize] Using model loss: cross-entropy
[2020-02-04:11:49:17:INFO:sockeye.training:_initialize] Using bucketing. Default max_seq_len=(100, 100)
[2020-02-04:11:49:17:INFO:sockeye.model:save_config] Saved config to "/Users/a.gogohia/Documents/GitHub/data_type_agnostic_imputation/data/german_credit_data/sockeye_model_large/config"
[2020-02-04:11:49:17:INFO:sockeye.lr_scheduler:__init__] Will reduce the learning rate by a factor of 0.70 whenever the validation score doesn't improve 8 times.
[2020-02-04:11:49:17:INFO:__main__:create_optimizer_config] Optimizer: Config[_frozen=False, gradient_clipping_threshold=1.0, gradient_clipping_type=none, initializer=<mxnet.initializer.Mixed object at 0x111e63f90>, kvstore=device, name=adam, params={'wd': 0.0, 'learning_rate': 0.0002, 'rescale_grad': 1.0, 'lr_scheduler': LearningRateSchedulerPlateauReduce(reduce_factor=0.70, reduce_num_not_improved=0)}, update_interval=1]
[2020-02-04:11:49:17:INFO:__main__:create_optimizer_config] Gradient Compression: None
[2020-02-04:11:49:17:INFO:sockeye.training:__init__] mxboard not found. Consider 'pip install mxboard' to log events to Tensorboard.
[2020-02-04:11:49:17:INFO:sockeye.checkpoint_decoder:__init__] Created CheckpointDecoder(max_input_len=-1, beam_size=5, model=german_credit_data/sockeye_model_large, num_sentences=100, context=cpu(0))
[2020-02-04:11:49:17:INFO:sockeye.training:fit] Early stopping by optimizing 'perplexity'
[2020-02-04:11:49:17:INFO:sockeye.training:log_parameters] Model parameters: decoder_transformer_0_att_enc_h2o_weight: (32, 32), decoder_transformer_0_att_enc_k2h_weight: (32, 48), decoder_transformer_0_att_enc_pre_norm_beta: (32,), decoder_transformer_0_att_enc_pre_norm_gamma: (32,), decoder_transformer_0_att_enc_q2h_weight: (32, 32), decoder_transformer_0_att_enc_v2h_weight: (32, 48), decoder_transformer_0_att_self_h2o_weight: (32, 32), decoder_transformer_0_att_self_i2h_weight: (96, 32), decoder_transformer_0_att_self_pre_norm_beta: (32,), decoder_transformer_0_att_self_pre_norm_gamma: (32,), decoder_transformer_0_ff_h2o_bias: (32,), decoder_transformer_0_ff_h2o_weight: (32, 16), decoder_transformer_0_ff_i2h_bias: (16,), decoder_transformer_0_ff_i2h_weight: (16, 32), decoder_transformer_0_ff_pre_norm_beta: (32,), decoder_transformer_0_ff_pre_norm_gamma: (32,), decoder_transformer_1_att_enc_h2o_weight: (32, 32), decoder_transformer_1_att_enc_k2h_weight: (32, 48), decoder_transformer_1_att_enc_pre_norm_beta: (32,), decoder_transformer_1_att_enc_pre_norm_gamma: (32,), decoder_transformer_1_att_enc_q2h_weight: (32, 32), decoder_transformer_1_att_enc_v2h_weight: (32, 48), decoder_transformer_1_att_self_h2o_weight: (32, 32), decoder_transformer_1_att_self_i2h_weight: (96, 32), decoder_transformer_1_att_self_pre_norm_beta: (32,), decoder_transformer_1_att_self_pre_norm_gamma: (32,), decoder_transformer_1_ff_h2o_bias: (32,), decoder_transformer_1_ff_h2o_weight: (32, 16), decoder_transformer_1_ff_i2h_bias: (16,), decoder_transformer_1_ff_i2h_weight: (16, 32), decoder_transformer_1_ff_pre_norm_beta: (32,), decoder_transformer_1_ff_pre_norm_gamma: (32,), decoder_transformer_2_att_enc_h2o_weight: (32, 32), decoder_transformer_2_att_enc_k2h_weight: (32, 48), decoder_transformer_2_att_enc_pre_norm_beta: (32,), decoder_transformer_2_att_enc_pre_norm_gamma: (32,), decoder_transformer_2_att_enc_q2h_weight: (32, 32), decoder_transformer_2_att_enc_v2h_weight: (32, 48), decoder_transformer_2_att_self_h2o_weight: (32, 32), decoder_transformer_2_att_self_i2h_weight: (96, 32), decoder_transformer_2_att_self_pre_norm_beta: (32,), decoder_transformer_2_att_self_pre_norm_gamma: (32,), decoder_transformer_2_ff_h2o_bias: (32,), decoder_transformer_2_ff_h2o_weight: (32, 16), decoder_transformer_2_ff_i2h_bias: (16,), decoder_transformer_2_ff_i2h_weight: (16, 32), decoder_transformer_2_ff_pre_norm_beta: (32,), decoder_transformer_2_ff_pre_norm_gamma: (32,), decoder_transformer_3_att_enc_h2o_weight: (32, 32), decoder_transformer_3_att_enc_k2h_weight: (32, 48), decoder_transformer_3_att_enc_pre_norm_beta: (32,), decoder_transformer_3_att_enc_pre_norm_gamma: (32,), decoder_transformer_3_att_enc_q2h_weight: (32, 32), decoder_transformer_3_att_enc_v2h_weight: (32, 48), decoder_transformer_3_att_self_h2o_weight: (32, 32), decoder_transformer_3_att_self_i2h_weight: (96, 32), decoder_transformer_3_att_self_pre_norm_beta: (32,), decoder_transformer_3_att_self_pre_norm_gamma: (32,), decoder_transformer_3_ff_h2o_bias: (32,), decoder_transformer_3_ff_h2o_weight: (32, 16), decoder_transformer_3_ff_i2h_bias: (16,), decoder_transformer_3_ff_i2h_weight: (16, 32), decoder_transformer_3_ff_pre_norm_beta: (32,), decoder_transformer_3_ff_pre_norm_gamma: (32,), decoder_transformer_final_process_norm_beta: (32,), decoder_transformer_final_process_norm_gamma: (32,), encoder_transformer_0_att_self_h2o_weight: (48, 48), encoder_transformer_0_att_self_i2h_weight: (144, 48), encoder_transformer_0_att_self_pre_norm_beta: (48,), encoder_transformer_0_att_self_pre_norm_gamma: (48,), encoder_transformer_0_ff_h2o_bias: (48,), encoder_transformer_0_ff_h2o_weight: (48, 16), encoder_transformer_0_ff_i2h_bias: (16,), encoder_transformer_0_ff_i2h_weight: (16, 48), encoder_transformer_0_ff_pre_norm_beta: (48,), encoder_transformer_0_ff_pre_norm_gamma: (48,), encoder_transformer_1_att_self_h2o_weight: (48, 48), encoder_transformer_1_att_self_i2h_weight: (144, 48), encoder_transformer_1_att_self_pre_norm_beta: (48,), encoder_transformer_1_att_self_pre_norm_gamma: (48,), encoder_transformer_1_ff_h2o_bias: (48,), encoder_transformer_1_ff_h2o_weight: (48, 16), encoder_transformer_1_ff_i2h_bias: (16,), encoder_transformer_1_ff_i2h_weight: (16, 48), encoder_transformer_1_ff_pre_norm_beta: (48,), encoder_transformer_1_ff_pre_norm_gamma: (48,), encoder_transformer_2_att_self_h2o_weight: (48, 48), encoder_transformer_2_att_self_i2h_weight: (144, 48), encoder_transformer_2_att_self_pre_norm_beta: (48,), encoder_transformer_2_att_self_pre_norm_gamma: (48,), encoder_transformer_2_ff_h2o_bias: (48,), encoder_transformer_2_ff_h2o_weight: (48, 16), encoder_transformer_2_ff_i2h_bias: (16,), encoder_transformer_2_ff_i2h_weight: (16, 48), encoder_transformer_2_ff_pre_norm_beta: (48,), encoder_transformer_2_ff_pre_norm_gamma: (48,), encoder_transformer_3_att_self_h2o_weight: (48, 48), encoder_transformer_3_att_self_i2h_weight: (144, 48), encoder_transformer_3_att_self_pre_norm_beta: (48,), encoder_transformer_3_att_self_pre_norm_gamma: (48,), encoder_transformer_3_ff_h2o_bias: (48,), encoder_transformer_3_ff_h2o_weight: (48, 16), encoder_transformer_3_ff_i2h_bias: (16,), encoder_transformer_3_ff_i2h_weight: (16, 48), encoder_transformer_3_ff_pre_norm_beta: (48,), encoder_transformer_3_ff_pre_norm_gamma: (48,), encoder_transformer_final_process_norm_beta: (48,), encoder_transformer_final_process_norm_gamma: (48,), source_embed_factor0_weight: (24, 16), source_embed_weight: (35, 32), target_embed_weight: (9, 32), target_output_bias: (9,), target_output_weight: (9, 32)
[2020-02-04:11:49:18:INFO:sockeye.training:log_parameters] Fixed model parameters: 
[2020-02-04:11:49:18:INFO:sockeye.training:log_parameters] Fixing 0 parameters (0.00%)
[2020-02-04:11:49:18:INFO:sockeye.training:log_parameters] Learning 88201 parameters (100.00%)
[2020-02-04:11:49:18:INFO:sockeye.training:log_parameters] Total # of parameters: 88201
[2020-02-04:11:49:18:INFO:root:save_params_to_file] Saved params to "/Users/a.gogohia/Documents/GitHub/data_type_agnostic_imputation/data/german_credit_data/sockeye_model_large/params.00000"
[2020-02-04:11:49:18:INFO:sockeye.training:fit] Training started.
[2020-02-04:11:49:22:INFO:sockeye.training:__call__] Epoch[0] Batch [50]	Speed: 43.42 samples/sec 3908.20 tokens/sec 10.86 updates/sec	perplexity=6.530038	accuracy=0.416667
[2020-02-04:11:49:27:INFO:sockeye.training:__call__] Epoch[0] Batch [100]	Speed: 43.01 samples/sec 3871.17 tokens/sec 10.75 updates/sec	perplexity=4.140786	accuracy=0.559765
[2020-02-04:11:49:31:INFO:sockeye.training:__call__] Epoch[0] Batch [150]	Speed: 43.84 samples/sec 3945.94 tokens/sec 10.96 updates/sec	perplexity=3.114352	accuracy=0.650923
[2020-02-04:11:49:36:INFO:sockeye.training:__call__] Epoch[0] Batch [200]	Speed: 44.53 samples/sec 4008.06 tokens/sec 11.13 updates/sec	perplexity=2.635838	accuracy=0.702020
[2020-02-04:11:49:40:INFO:sockeye.training:__call__] Epoch[1] Batch [250]	Speed: 45.32 samples/sec 4078.49 tokens/sec 11.33 updates/sec	perplexity=2.360510	accuracy=0.736540
[2020-02-04:11:49:45:INFO:sockeye.training:__call__] Epoch[1] Batch [300]	Speed: 43.82 samples/sec 3943.83 tokens/sec 10.96 updates/sec	perplexity=2.172938	accuracy=0.764664
[2020-02-04:11:49:49:INFO:sockeye.training:__call__] Epoch[1] Batch [350]	Speed: 45.06 samples/sec 4055.27 tokens/sec 11.26 updates/sec	perplexity=2.042787	accuracy=0.783792
[2020-02-04:11:49:54:INFO:sockeye.training:__call__] Epoch[1] Batch [400]	Speed: 43.35 samples/sec 3901.11 tokens/sec 10.84 updates/sec	perplexity=1.944457	accuracy=0.799042
[2020-02-04:11:49:58:INFO:sockeye.training:__call__] Epoch[2] Batch [450]	Speed: 45.27 samples/sec 4074.33 tokens/sec 11.32 updates/sec	perplexity=1.870372	accuracy=0.810888
[2020-02-04:11:50:03:INFO:sockeye.training:__call__] Epoch[2] Batch [500]	Speed: 45.58 samples/sec 4102.31 tokens/sec 11.40 updates/sec	perplexity=1.809350	accuracy=0.819829
[2020-02-04:11:50:07:INFO:sockeye.training:__call__] Epoch[2] Batch [550]	Speed: 44.59 samples/sec 4013.42 tokens/sec 11.15 updates/sec	perplexity=1.757739	accuracy=0.829929
[2020-02-04:11:50:12:INFO:sockeye.training:__call__] Epoch[2] Batch [600]	Speed: 43.48 samples/sec 3913.17 tokens/sec 10.87 updates/sec	perplexity=1.717156	accuracy=0.837783
[2020-02-04:11:50:17:INFO:sockeye.training:__call__] Epoch[2] Batch [650]	Speed: 36.44 samples/sec 3279.20 tokens/sec 9.11 updates/sec	perplexity=1.682135	accuracy=0.844648
[2020-02-04:11:50:22:INFO:sockeye.training:__call__] Epoch[3] Batch [700]	Speed: 42.86 samples/sec 3857.84 tokens/sec 10.72 updates/sec	perplexity=1.652237	accuracy=0.850145
[2020-02-04:11:50:27:INFO:sockeye.training:__call__] Epoch[3] Batch [750]	Speed: 44.61 samples/sec 4015.33 tokens/sec 11.15 updates/sec	perplexity=1.626107	accuracy=0.855216
[2020-02-04:11:50:31:INFO:sockeye.training:__call__] Epoch[3] Batch [800]	Speed: 45.26 samples/sec 4072.96 tokens/sec 11.31 updates/sec	perplexity=1.604116	accuracy=0.859007
[2020-02-04:11:50:35:INFO:sockeye.training:__call__] Epoch[3] Batch [850]	Speed: 46.12 samples/sec 4151.02 tokens/sec 11.53 updates/sec	perplexity=1.583292	accuracy=0.863272
[2020-02-04:11:50:40:INFO:sockeye.training:__call__] Epoch[4] Batch [900]	Speed: 44.79 samples/sec 4031.34 tokens/sec 11.20 updates/sec	perplexity=1.566452	accuracy=0.866391
[2020-02-04:11:50:44:INFO:sockeye.training:__call__] Epoch[4] Batch [950]	Speed: 45.33 samples/sec 4079.40 tokens/sec 11.33 updates/sec	perplexity=1.549662	accuracy=0.870364
[2020-02-04:11:50:49:INFO:sockeye.training:__call__] Epoch[4] Batch [1000]	Speed: 42.96 samples/sec 3866.19 tokens/sec 10.74 updates/sec	perplexity=1.534954	accuracy=0.873550
[2020-02-04:11:50:53:INFO:sockeye.training:__call__] Epoch[4] Batch [1050]	Speed: 43.61 samples/sec 3924.95 tokens/sec 10.90 updates/sec	perplexity=1.522492	accuracy=0.876103
[2020-02-04:11:50:58:INFO:sockeye.training:__call__] Epoch[4] Batch [1100]	Speed: 43.80 samples/sec 3941.88 tokens/sec 10.95 updates/sec	perplexity=1.511013	accuracy=0.878364
[2020-02-04:11:51:03:INFO:sockeye.training:__call__] Epoch[5] Batch [1150]	Speed: 43.29 samples/sec 3896.48 tokens/sec 10.82 updates/sec	perplexity=1.499903	accuracy=0.880741
[2020-02-04:11:51:07:INFO:sockeye.training:__call__] Epoch[5] Batch [1200]	Speed: 42.48 samples/sec 3823.63 tokens/sec 10.62 updates/sec	perplexity=1.490288	accuracy=0.882478
[2020-02-04:11:51:12:INFO:sockeye.training:__call__] Epoch[5] Batch [1250]	Speed: 42.60 samples/sec 3833.60 tokens/sec 10.65 updates/sec	perplexity=1.480817	accuracy=0.884506
[2020-02-04:11:51:17:INFO:sockeye.training:__call__] Epoch[5] Batch [1300]	Speed: 44.24 samples/sec 3981.51 tokens/sec 11.06 updates/sec	perplexity=1.472736	accuracy=0.886176
[2020-02-04:11:51:21:INFO:sockeye.training:__call__] Epoch[6] Batch [1350]	Speed: 45.23 samples/sec 4070.90 tokens/sec 11.31 updates/sec	perplexity=1.464353	accuracy=0.888166
[2020-02-04:11:51:25:INFO:sockeye.training:__call__] Epoch[6] Batch [1400]	Speed: 45.61 samples/sec 4104.85 tokens/sec 11.40 updates/sec	perplexity=1.457204	accuracy=0.889755
[2020-02-04:11:51:30:INFO:sockeye.training:__call__] Epoch[6] Batch [1450]	Speed: 45.12 samples/sec 4060.91 tokens/sec 11.28 updates/sec	perplexity=1.450566	accuracy=0.890938
[2020-02-04:11:51:34:INFO:sockeye.training:__call__] Epoch[6] Batch [1500]	Speed: 44.18 samples/sec 3976.11 tokens/sec 11.04 updates/sec	perplexity=1.444991	accuracy=0.891904
[2020-02-04:11:51:39:INFO:sockeye.training:__call__] Epoch[6] Batch [1550]	Speed: 43.69 samples/sec 3931.98 tokens/sec 10.92 updates/sec	perplexity=1.439049	accuracy=0.893174
[2020-02-04:11:51:43:INFO:sockeye.training:__call__] Epoch[7] Batch [1600]	Speed: 44.08 samples/sec 3966.79 tokens/sec 11.02 updates/sec	perplexity=1.432648	accuracy=0.894858
[2020-02-04:11:51:48:INFO:sockeye.training:__call__] Epoch[7] Batch [1650]	Speed: 43.72 samples/sec 3935.16 tokens/sec 10.93 updates/sec	perplexity=1.427359	accuracy=0.896046
[2020-02-04:11:51:53:INFO:sockeye.training:__call__] Epoch[7] Batch [1700]	Speed: 43.60 samples/sec 3924.22 tokens/sec 10.90 updates/sec	perplexity=1.422643	accuracy=0.896989
[2020-02-04:11:51:58:INFO:sockeye.training:__call__] Epoch[7] Batch [1750]	Speed: 40.22 samples/sec 3619.64 tokens/sec 10.05 updates/sec	perplexity=1.418033	accuracy=0.897924
[2020-02-04:11:52:02:INFO:sockeye.training:__call__] Epoch[8] Batch [1800]	Speed: 41.57 samples/sec 3740.96 tokens/sec 10.39 updates/sec	perplexity=1.413617	accuracy=0.898935
[2020-02-04:11:52:07:INFO:sockeye.training:__call__] Epoch[8] Batch [1850]	Speed: 43.19 samples/sec 3887.02 tokens/sec 10.80 updates/sec	perplexity=1.409309	accuracy=0.900037
[2020-02-04:11:52:11:INFO:sockeye.training:__call__] Epoch[8] Batch [1900]	Speed: 45.42 samples/sec 4087.77 tokens/sec 11.35 updates/sec	perplexity=1.405465	accuracy=0.900690
[2020-02-04:11:52:16:INFO:sockeye.training:__call__] Epoch[8] Batch [1950]	Speed: 43.84 samples/sec 3945.55 tokens/sec 10.96 updates/sec	perplexity=1.401509	accuracy=0.901590
[2020-02-04:11:52:20:INFO:sockeye.training:__call__] Epoch[8] Batch [2000]	Speed: 44.76 samples/sec 4028.02 tokens/sec 11.19 updates/sec	perplexity=1.397337	accuracy=0.902710
[2020-02-04:11:52:25:INFO:sockeye.training:__call__] Epoch[9] Batch [2050]	Speed: 44.65 samples/sec 4018.66 tokens/sec 11.16 updates/sec	perplexity=1.393906	accuracy=0.903414
